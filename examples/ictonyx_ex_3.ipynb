{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956d5c62-7758-4699-a71d-1e05f35ded44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 21:39:43.388506: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-23 21:39:43.415630: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-23 21:39:43.859472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is available. Proceeding with the example.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Check for TensorFlow and other dependencies\n",
    "import ictonyx\n",
    "\n",
    "if not ictonyx.TENSORFLOW_AVAILABLE:\n",
    "    print(\"TensorFlow is not installed. Please install it with: pip install tensorflow\")\n",
    "else:\n",
    "    print(\"TensorFlow is available. Proceeding with the example.\")\n",
    "\n",
    "from ictonyx.data import DataHandler\n",
    "from ictonyx.core import KerasModelWrapper\n",
    "from ictonyx.config import ModelConfig\n",
    "from ictonyx.runners import ExperimentRunner\n",
    "from ictonyx.loggers import BaseLogger\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af23e70-ba79-4e29-81e5-9a1bd9cbc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading and Preparation ---\n",
    "class MNISTDataHandler(DataHandler):\n",
    "    \"\"\"A custom DataHandler to load and preprocess the built-in MNIST dataset.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def data_type(self) -> str:\n",
    "        return \"image\"\n",
    "\n",
    "    @property\n",
    "    def return_format(self) -> str:\n",
    "        return \"split_arrays\"\n",
    "        \n",
    "    def __init__(self):\n",
    "        # We don't need a data_path for this handler, but the parent class\n",
    "        # expects one. We'll pass a placeholder and then override the validation.\n",
    "        super().__init__(data_path=\"\")\n",
    "\n",
    "    def _validate_data_path(self):\n",
    "        # We intentionally override the parent's validation because we are\n",
    "        # loading a built-in dataset, not a file from disk.\n",
    "        pass\n",
    "\n",
    "    def load(self, validation_split: float = 0.2, **kwargs) -> dict:\n",
    "        \"\"\"Loads and preprocesses the MNIST dataset.\"\"\"\n",
    "        print(\"Loading MNIST data from TensorFlow...\")\n",
    "        (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "        # Reshape data for CNN input (batch, height, width, channels)\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "        X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "        # Normalize pixel values from [0, 255] to [0.0, 1.0]\n",
    "        X_train = X_train.astype(\"float32\") / 255.0\n",
    "        X_test = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "        # Split training data into training and validation sets\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=validation_split, random_state=42\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'train_data': (X_train, y_train),\n",
    "            'val_data': (X_val, y_val),\n",
    "            'test_data': (X_test, y_test)\n",
    "        }\n",
    "\n",
    "# Instantiate our custom data handler\n",
    "mnist_handler = MNISTDataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd07328d-14c0-48e3-8ed1-4f2fc51b9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Definition ---\n",
    "def create_simple_cnn(config: ModelConfig) -> KerasModelWrapper:\n",
    "    \"\"\"Builds a simple CNN for MNIST classification.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return KerasModelWrapper(model)\n",
    "\n",
    "# --- Model Configuration ---\n",
    "model_config = ModelConfig({\n",
    "    'epochs': 5,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce2134b-2b03-40e7-ada9-fa4fde247446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_variability_study() got an unexpected keyword argument 'logger'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Run the Experiment ---\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Run a variability study with 4 runs\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m study_results \u001b[38;5;241m=\u001b[39m \u001b[43mictonyx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_variability_study\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_builder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_simple_cnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmnist_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBaseLogger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Print a summary of the results\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: run_variability_study() got an unexpected keyword argument 'logger'"
     ]
    }
   ],
   "source": [
    "# --- Run the Experiment ---\n",
    "# Run a variability study with 4 runs\n",
    "study_results = ictonyx.run_variability_study(\n",
    "    model_builder=create_simple_cnn,\n",
    "    data_handler=mnist_handler,\n",
    "    model_config=model_config,\n",
    "    num_runs=4,\n",
    "    logger=BaseLogger()\n",
    ")\n",
    "\n",
    "# Print a summary of the results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Experiment Complete: Summary of Final Results\")\n",
    "print(study_results.summarize())\n",
    "\n",
    "# Get a DataFrame of the final metrics for a more detailed view\n",
    "results_df = study_results.to_dataframe()\n",
    "print(\"\\nFinal Metrics DataFrame:\")\n",
    "print(results_df)\n",
    "\n",
    "# --- Analysis ---\n",
    "# 5.1. Plotting the training histories\n",
    "all_histories = study_results.all_runs_metrics\n",
    "from ictonyx.plotting import plot_variability_summary\n",
    "\n",
    "print(\"\\nPlotting Variability Summary...\")\n",
    "plot_variability_summary(\n",
    "    all_runs_metrics_list=all_histories,\n",
    "    final_metrics_series=study_results.final_val_accuracies,\n",
    "    metric='accuracy',\n",
    "    show_boxplot=True\n",
    ")\n",
    "\n",
    "# 5.2. Statistical Comparison of Runs\n",
    "print(\"\\nPerforming Statistical Comparison of Runs...\")\n",
    "statistical_comparison = study_results.compare_models_statistically(\n",
    "    metric_name='val_accuracy'\n",
    ")\n",
    "\n",
    "overall_result = statistical_comparison['overall_test']\n",
    "\n",
    "print(\"\\nOverall Statistical Test Result:\")\n",
    "print(f\"Test Name: {overall_result.test_name}\")\n",
    "print(f\"Statistic: {overall_result.statistic:.4f}\")\n",
    "print(f\"P-value: {overall_result.p_value:.4f}\")\n",
    "\n",
    "if overall_result.is_significant():\n",
    "    print(\"Conclusion: There is a statistically significant difference between the runs.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no statistically significant difference between the runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf4a84-b522-4f39-891f-e1dd298b75fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
